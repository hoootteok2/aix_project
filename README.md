Title: YOLOv7을 이용한 수어 번역기
==========
Members
===========
* 송서빈 
* 이예림

I. Proposal (Option 1)
=============================
- Motivation: Why are you doing this?
소통을 하고자 하는 것은 인간의 기본적인 욕구입니다. 음성 언어로 소통하지 못하는 특수한 사람들의 상황을 반영하여, 소통을 가능하게 하려는 동기에서 프로젝트를 시작하였습니다.
평범한 이들이 소통하는 방식 이외의 방법으로 소통할 수 있는 가능성을 보여줌으로써, 평등한 인류를 도모하고, 소통을 위한 각자의 방식이 있을 수 있음을 역설하고자 합니다.

- What do you want to see at the end?
웹캠에서 손동작을 yolov7을 통해 object detection 한 후, 의미를 텍스트로 디스플레이
  
II. Datasets
======================================
- Describing your dataset
https://public.roboflow.com/object-detection/american-sign-language-letters/1
https://www.kaggle.com/datasets/grassknoted/asl-alphabet
https://universe.roboflow.com/david-lee-d0rhs/american-sign-language-letters
1) explain dataset

2) explain yolov7-object detection


III. Methodology & Results
========================
1) 실행환경


2) 실행코드(prompt/python)

3) algorithm

4) Results
video
result model



- Explaining your choice of algorithms (methods)
- Explaining features (if any)
- 
IV. Evaluation & Analysis
=====================
- Graphs, tables, any statistics (if any)
  1) model accuracy updated graph
  2) 
- 
V. Related Work (e.g., existing studies)
==================
- https://public.roboflow.com/object-detection/american-sign-language-letters
for asl dataset recognition
- opencv
for display algorithm
  
- Tools, libraries, blogs, or any documentation that you have used to do this project.
- 
VI. Conclusion: Discussion
=======================
